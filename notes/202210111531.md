# Residual sum of squares

Convenient to consider the Euclidean distance between the observed output vs the
predicted output as a form of loss function, $\|\bold{y} - \bold{\hat{y}}\|^2$.
This is known as the Euclidean, or L2, norm. To get our loss function, we sum
the norms as (using the notation from [linear models](202210111445.md)):
$$
\sum_{n=1}^{n} \|y_i - \hat{y}_i\|^2 = \sum_{n=1}^{n} \|y_i - \bold{x}_i \cdot
\bold{w}\|^2 = \|\bold{X}\bold{w} - \bold{y}\|^2
$$
