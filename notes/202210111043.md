# Bayesian normal fitting

Unlike the [maximum likelihood](202210101331) and [MAP](202210101339), which
seek to estimate the best fitting single fixed values (or point estimates) of
the parameters $\boldsymbol{\theta}$, here we instead compute a probability
distribution $Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I})$ with

$$
Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I}) = \frac{\prod_{n=1}^{I} Pr(\bold{x}_i|\boldsymbol{\theta})Pr(\boldsymbol{\theta}) }
{Pr(\bold{x}_{1 \ldots I})}
$$

Evaluating the [predictive distribution](202210131442) is more difficult here
since we have not estimated a single model but have instead found a probability
distribution over possible models. Hence we calculate
$$
Pr(\bold{x}^*|\bold{x}_{1 \ldots I}) = \int
Pr(\bold{x}^*|\boldsymbol{\theta})Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots
I})d\boldsymbol{\theta}
$$

This can be thought of as: the term $Pr(\bold{x}^*|\bold{x}_{1 \ldots I})$ is
the prediction for a given value of $\boldsymbol{\theta}$. So, the integral can
be thought of as the weighted sum of the predictions given by different
parameters $\boldsymbol{\theta}$, where weighting is determined by the posterior
probability distribution $Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I})$ over
the parameters (representing our confidence that different parameters are
correct).

### Example: univariate normal

Using the [normal inverse gamma distribution](202210091117) as the prior, we get

$$
Pr(\mu, \sigma^2|x_{1 \ldots I}) =
\text{NormInvGam}_{\mu,\sigma^2}[\tilde{\alpha}, \tilde{\beta}, \tilde{\gamma}, \tilde{\delta}]
$$

Where

$$
\begin{align*}
\tilde{\alpha} &= \alpha + I/2 \\[0.5em]
\tilde{\gamma} &= \alpha + I \\[0.5em]
\tilde{\delta} &= \frac{(\gamma \delta + \sum_{i} x_i)}{\gamma + I} \\[0.5em]
\tilde{\beta} &= \frac{\sum_{i} x_i^2}{2} + \beta + \frac{\gamma \delta^2}{2}
- \frac{(\gamma \delta + \sum_{i} x_i)^2}{2(\gamma + I)}
\\[0.5em]
\end{align*}
$$


This represents the relative plausibility of various parameter settings $\mu$
and $\sigma^2$ having created the data.
