# Bayesian normal fitting

Unlike the [maximum likelihood](202210101331) and [MAP](202210101339), which
seek to estimate the best fitting single fixed values (or point estimates) of
the parameters $\boldsymbol{\theta}$, here we instead compute a probability
distribution $Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I})$ with

$$
Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I}) = \frac{\prod_{n=1}^{I} Pr(\bold{x}_i|\boldsymbol{\theta})Pr(\boldsymbol{\theta}) }
{Pr(\bold{x}_{1 \ldots I})}
$$

Evaluating the [predictive distribution](202210131442) is more difficult here
since we have not estimated a single model but have instead found a probability
distribution over possible models. Hence we calculate 
$$
Pr(\bold{x}^*|\bold{x}_{1 \ldots I}) = \int
Pr(\bold{x}^*|\boldsymbol{\theta})Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots
I})d\boldsymbol{\theta}
$$

This can be thought of as: the term $Pr(\bold{x}^*|\bold{x}_{1 \ldots I})$ is
the prediction for a given value of $\boldsymbol{\theta}$. So, the integral can
be thought of as the weighted sum of the predictions given by different
parameters $\boldsymbol{\theta}$, where weighting is determined by the posterior
probability distribution $Pr(\boldsymbol{\theta}|\bold{x}_{1 \ldots I})$ over
the parameters (representing our confidence that different parameters are
correct).

### Example: univariate normal

Using the [normal inverse gamma distribution](202210091117) as the prior, we get

$$
Pr(\mu, \sigma^2|x_{1 \ldots I}) =
\text{NormInvGam}_{\mu,\sigma^2}[\overline{\alpha}, \overline{\beta}, \overline{\gamma}, \overline{\delta}]
$$

This represents the relative plausibility of various parameter settings $\mu$
and $\sigma^2$ having created the data.

