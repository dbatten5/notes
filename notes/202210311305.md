# Logistic regression

This is a [discriminative model](202210171323.md) that can be used for
[classification](202210061320.md).

For a binary classification, good to use the [Bernoulli distribution](202210081016.md)
over the world $\bold{w}$ with $P(w = 1) = \lambda$.

$$
P(w|\phi_0, \boldsymbol{\phi}, \bold{x}) = \text{Bern}_w\left[ \text{sig} \left[ a \right]
\right]
$$

With $\text{sig}$ being the [sigmoid](202210141123.md) and we model activation
with a linear function:

$$
a = \phi_0 + \boldsymbol{\phi}^{\top}\bold{x}
$$

We have two parameters:

$$
\boldsymbol{\theta} = \left\{ \phi_0, \phi_1 \right\}
$$

Can learn these through the normal methods (ML, MAP, Bayesian, etc.). For
inference, just evaluate $P(\bold{w}|\bold{x})$ for our new datum $\bold{x}$.

We follow the same notation tidy up as [linear regression](202210241230.md) and
end up with a new activation $a = \boldsymbol{\phi}^{\top}\bold{x}$ and a new
model:

$$
P(w|\boldsymbol{\phi}, \bold{x}) = \text{Bern}_w
\left[ \frac{1}{1 + \exp\left[ -\boldsymbol{\phi}^{\top}\bold{x} \right]} \right]
$$

With $a_i = \boldsymbol{\phi}^{\top}\bold{x}_i$.

### ML

We have

$$
P(\bold{w}|\bold{X},\boldsymbol{\psi}) = \prod_{i=1}^{I} \lambda^{w_i}
(1 - \lambda)^{1 - w_i}
$$


There's no closed form solution to solve for

$$
\frac{\partial L}{\partial \phi}  = -\sum_{i=1}^{I} \left(
\text{sig}\left[ a_i \right] - w_i
\right)\bold{x}_i = 0
$$

Have to use [iterative non-linear optimization](202210311318.md).
