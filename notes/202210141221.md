# Stochastic gradient descent

Instead of calculating the loss gradient for the entire training set, you do it
in small stages, one sample at a time.

1. start somewhere
2. calculate the gradient for one sample in the training set
3. take a small step down the gradient
4. check if at the minimum
5. if not, repeat from step 2 but with a different sample

Like [batch](202210141216.md), still need to pick a learning rate and starting
point, but is much less expensive. A middle-ground here is [mini-batch gradient](202210141225.md).

Each update here is fully determined by a single sample. On average, over the
whole population, you'd expect samples gradients to be pointing in the right direction,
but individual samples may be pointing all over the place. The steepness of the
gradient may be drastically different in some directions than others, meaning
that the learning rates will have to be balanced in different directions, which
could case a slowdown in performance. To counter this, a notion of [momentum](202210141240.md) 
is added, which can reduce noise and oscillations and even help to ensure that
the method doesn't get stuck in local minima.
