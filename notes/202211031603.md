# Binary cross-entropy loss

$$
L(y, \hat{y}) = -\left[ 
y\log\hat{y} + (1 - y)\log(1 - \hat{y})
\right]
$$

Its derivative is

$$
L'(y, \hat{y}) = \frac{\hat{y} - y}
{\hat{y}(1 - \hat{y})}
$$

