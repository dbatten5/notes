# Naive Bayes classifier

This is a form of [generative modelling](202210171325.md) of the form

$$
p(\bold{x}, c) = p(c)\prod_{i=1}^{D} p(x_i|c)
$$

The central assumption is that given a class $c$, the attributes $x_i$ are
independent.

### Example

Consider the following vector of attributes:

$$
(x_1, x_2, x_3, x_4, x_5)
$$

Where e.g. $x_1 =$ likes shortbread. Together with each vector $\bold{x}$ there
is a label $nat$ describing the nationality of the person, 
$\text{dom}(nat) = \left\{ \text{scottish, english} \right\}$. We can use Bayes'
rule to calculate the probability that $\bold{x}$ is Scottish or English:

$$
\begin{align*}
p(s|\bold{x}) &= \frac{p(\bold{x}|s)p(s)}{p(\bold{x})} \\[0.5em]
&= \frac{p(\bold{x}|s)p(s)}
{p(\bold{x}|s)p(s) + p(\bold{x}|e)p(e)} \\[0.5em]
\end{align*}
$$

For $p(\bold{x}|nat)$ under the Naive Bayes assumption:

$$
p(\bold{x}|nat) = p(x_1|nat)p(x_2|nat)p(x_3|nat)p(x_4|nat)p(x_5|nat)
$$

