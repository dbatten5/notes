# Generalised linear model

We do a "two-stage" model. Use a linear predictor as a meta-parameter, then
transform it to get the parameter(s) of the target distribution. This
transformation will be called a *link function*.

So for [Bernoulli](202210081016.md), we enforce the parameter to be in $\left[
0, 1 \right]$, for [Poisson](202210081412.md), we enforce it to be in $(0,
\infty)$.

The generic way of writing them down for $Y \backsim F(\theta)$

$$
\begin{align*}
\theta^{(i)} &= g^{-1}(\eta^{(i)}) \\[0.5em]
\eta^{(i)} &= \sum_{j=1}^{p} x_j^{(i)}\beta_j
\end{align*}
$$

How do you recover various different models from this? For e.g. binary
classification, i.e. $Y \in \left\{ 0, 1 \right\}$, we need to select a model
$(F)$ that has two outcomes. Most common to use here is a
[Bernoulli](202210081016.md) with parameter $\theta$. For countable data $Y$,
could use [Poisson](202210081412.md) or negative binomial. The link function $g$
is only important if we need to ensure some constraint on the parameter
$\theta$, for example for Poisson we need to ensure that $\theta \in \{1,2,\ldots \infty\}$.

## Examples

### Logistic / Bernoulli

Suppose we have a [logistic regression](202210311305.md) with a
[Bernoulli distribution](202210081016.md).

$$
P(Y = y) = \theta^y(1 - \theta)^{1-y}, y \in \left\{ 0, 1 \right\} \\[0.5em]
\eta^{(i)} = \sum_{j=1}^{p} x_j^{(i)}\beta_j \\[0.5em]
\eta^{(i)} = g(\theta^{(i)})
$$

Here, $g$ is the link function. How should we pick this link function?

We often use the [logit](202211040918.md) link function, since its inverse is
the [logistic function](202210141123.md):

$$
\theta = g^{-1}(\eta) \equiv \frac{1}{1 + e^{-\eta}}
$$

This is equivalent to

$$
\underbrace{\log \frac{P(Y = 1|X = x)}{P(Y = 0|X = x)}}_{\text{called "log-odds"}} =
\beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p
$$

If $x_1$ increases by one unit, the log-odds for $Y$ increases by $\beta_1$

### [Poisson](202210081412.md)

We have

$$
P(Y = y) = \frac{\theta^y e^{-\theta}}{y!}, y \in \left\{ 0, 1, 2, 3, \ldots \right\}
$$

And

$$
\eta^{(i)} = \sum_{j=1}^{p} x_j^{(i)}\beta_j
$$

What should we use for our link function? Need to make sure it maps $\eta$ to
$>0$. Typically we'll take

$$
\theta^{(i)} \equiv \exp \left( \sum_{j=1}^{p} x_j^{(i)}\beta_j \right)
$$

This gives us a mapping between the linear response and the log-conditional
expected value of $Y$:

$$
\log \mathbb{E}[Y|X=x] = \log \theta = \sum_{j=1}^{p} x_j\beta_j
$$

Each coefficient $\beta_j$ is the rate of change of the expected value of the
outcome on log-scale per unit of $X_j$, fixing everything else.

### [Ordinal](202211041135.md)

This can be achieved with an [ordered logit model](202211041136.md). We
interpret it as

$$
Z^{(i)} = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p + \epsilon^{(i)}
$$


$$
y^{(i)} = \begin{cases}
1, \hspace{2.5em} \text{if } z^{(i)} < 0 \\
2, \hspace{2.5em} \text{if } z^{(i)} \in (0, c_2) \\
3, \hspace{2.5em} \text{if } z^{(i)} \in (c_2, c_3) \\
\hspace{3.5em} \vdots \\
K - 1, \hspace{0.5em} \text{if } z^{(i)} \in (c_{K - 2}, c_{K - 1}) \\
K, \hspace{2.2em} \text{if } z^{(i)} > c_{K - 1}
\end{cases}
$$


