# Expectation maximization

The EM algorithm is used to find [maximum likelihood](202210101331.md) or
[MAP](202210101339.md) estimates of model parameters $\boldsymbol{\theta}$. It is
especially useful when there are no closed form solutions for ML and MAP.

$$
\begin{equation}
\hat{\boldsymbol{\theta}} = \argmax_{\boldsymbol{\theta}} \left[
\sum_{i=1}^{I} \log \left[
\int P(\bold{x}_i, \bold{h}_i|\boldsymbol{\theta}) d\bold{h}_i
\right]
\right]
\end{equation}
$$

It works by defining a lower bound $\mathcal{B}[\{q_i(\bold{h}_i)\}, \boldsymbol{\theta}]$
on $(1)$ and iteratively increasing this bound. The lower bound chosen is

$$
\begin{equation}
\mathcal{B}[\{q_i(\bold{h}_i)\}, \boldsymbol{\theta}] =
\sum_{i=1}^{I} \int q_i(\bold{h}_i) \log \left[
\frac{P(\bold{x}_i, \bold{h}_i|\theta)}{q_i(\bold{h}_i)}
\right] d\bold{h}_i
\end{equation}
$$

Here, $\{q_i(\bold{h}_i)\}_{i=1}^I$ are the set of $I$ probability distributions
over the hidden variables $\{\bold{h}_i\}_{i=1}^I$.

The EM algorithm manipulates both $\boldsymbol{\theta}$ and the distributions
$\{q_i(\bold{h}_i)\}_{i=1}^I$ to increase the lower bound. It alternates
between:

* updating the probability distributions $\{q_i(\bold{h}_i)\}_{i=1}^I$ to
  improve the bound in $(2)$. This is known as the *expectation step* or
  [E-step](202210250945.md).
* updating the parameters $\boldsymbol{\theta}$ to improve the bound in $(2)$.
  This is known as the maximization step or [M-step](202210250946.md).

The E- and M-steps are alternated until the bound on the data no longer
increases and the parameters no longer change.

### Lower bound

Using [Jensen's inequality](202211241115.md), we have

$$
\log p(v|\theta) \ge \lang \log p(v,h|\theta) \rang_{q(h)} + H(q)
$$

The RHS is called free energy and is a function $F(q,\theta)$. Much easier to
optimise the free energy rather than the likelihood.

For the E-step, note that we can rewrite free energy as

$$
\log p(v|\theta) - KL(q(h)||p(h|v,\theta))
$$

So the optimal setting is $q(h) = p(h|v,\theta)$.

For the M-step

$$
\theta_{new} = \argmax_{\theta} \left< 
\log p(v,h|\theta)
\right>_{q(h)}
$$

Where $q(h) = p(h|v,\theta_{old})$

### Example

A single visible variable $v$ and a single two-state hidden variable
$h \in \left\{ 1, 2 \right\}$. We define $p(v,h) = p(v|h)p(h)$ with

$$
p(v|h,\theta) = \frac{1}{\sqrt{2 \pi \sigma^2}}
\exp \left[-
\frac{1}{2\sigma^2}(v - \theta h)^2
\right]
$$

and $p(h = 1) = p(h = 2) = 0.5$. For an observation $v = 2.75$ and
$\sigma^2 = 0.5$, want to find $\theta$ that optimises the likelihood

$$
p(v = 2.72|\theta) = \frac{1}{2\sqrt{\pi}} \sum_{h=1,2}
\exp \left[ -(2.75 - \theta h)^2 \right]
$$

The lower bound, as a function of $\theta$ and $q$ is

$$
\log p(v = 2.72|\theta) \ge LB(q(h = 2), \theta)
$$

Note that we only need $q(h=2)$ since $q(h=1) = 1 - q(h=2)$.

$$
LB(q(h=2),\theta) \equiv
\underbrace{-q(h=1)\log q(h=1) - q(h=2)\log q(h=2)}_{\text{entropy }H(q)} -
\sum_{h=1,2} q(h)(2.75 - \theta h)^2 + \log 2
$$

For the M-step we want to minimize w.r.t. $\theta$. So differentiate the RHS
above and set to 0, resulting in

$$
\theta = v\left< h \right>_{q(h)} / \left< h^2 \right>_{q(h)}
$$

For the E-step

$$
q^{new}(h) = p(h|v,\theta)
$$

so that

$$
q^{new}(h=2) = \frac{p(v=2.75|h=2,\theta)p(h=2)}{p(v=2.75)}
$$

