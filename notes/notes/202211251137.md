# Generalised additive models

Common to have multiple covariates. In this instance can use 
[tensor product basis](202211251218.md).

However, this gets complex very quickly due to high dimensionality. An
alternative is to use an **additive model**: one basis function per covariate.

$$
\begin{equation}
Y = \beta_0 + \sum_{j=1}^{p} f_j(x_j) + \epsilon
\end{equation}
$$

For $f_j$, typically $\sum_{i=1}^{n} f(x_j^{(i)}) = 0$ is enforced. $(1)$ will
result in $p$ different basis functions.

## Backfitting algorithm

1. Initialize $\hat{\alpha} = \frac{1}{N}\sum_{1}^{N} y_i, \hspace{0.5em} \hat{f}_j \equiv 0,
   \hspace{0.5em} \forall i,j$
2. Cycle: $j = 1, 2, \ldots, p, \ldots, 1, 2, \ldots, p, \ldots,$

$$
\hat{f}_j \leftarrow \mathcal{S}_j \left[ 
\left\{ y_i - \hat{\alpha} - \sum_{k\ne j} \hat{f}_k(x_{ik}) \right\}^N_1
\right]
$$

$$
\hat{f}_j \leftarrow \hat{f}_j - \frac{1}{N}\sum_{i=1}^{N} \hat{f}_j(x_{ij})
$$

until the functions $\hat{f}_j$ change less than a prespecified threshold. Here,
$\mathcal{S}$ is a smoother, e.g. natural smoothing splines.


$$
\beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3 + \beta_4x^4 + \epsilon
$$

