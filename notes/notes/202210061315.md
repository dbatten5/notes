# Types of data

Important that we don't test a model on data that it has already seen. With that
in mind, the dataset is often split into two, a **training** set and a **test** set.
Of course, we need enough data in the training set to properly train the model.
Typically it'll be around 80% of the data in the training set and 20% in the
test set.

Often want to check our code works, tune our hyperparameters, etc. Typically
another chunk is reserved for that purpose, known as a **validation** set. Split
could be 70% for training, 10% for validation and 20% for testing.

If the output type of a model is continuous, then the problem is called
**[regression](202210061318.md)** and a distance based loss function is often used.

If the output is discrete, then the problem is called
**[classification](202210061320.md)** and we often use an information based loss,
eg. cross-entropy. These are often thought of in terms of probability.

In most cases, models expect a numerical input, so it is therefore important to
have a way to convert from categorical to numerical variables. Often not a good
idea to assign a number to a category as the numbers have no meaning. Instead
it's advised to split out the different classes into separate feature
dimensions, or **indicator variables.** For example, instead of having a single
dimension representing film genre, which can take on values of "action",
"comedy", etc. it's preferable to have a dimension for each of the values and a
1 or 0 to represent whether it satisfies that criteria, eg. an "action"
dimension and a "comedy" dimension. Indicator variables often have the following
notation
$$
\bold{1}(x = \text{"horror"}) = \begin{cases}
  1 & \text{if } x = \text{"horror"} \\
  0 & \text{otherwise}
\end{cases}
$$

