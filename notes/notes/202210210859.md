# Perceptron

A linear [binary classification](202210141045.md) model. The algorithm looks like
so:

- Initialise a weight vector $\bold{w}$ to 0: $\bold{w} \larr 0$
- For each sample $\bold{x}$ in the training set:
    - Make a prediction based on the current weight vector: $\hat{y} \larr \bold{1}(\bold{x} \cdot \bold{w} \ge 0)$
    - Update the weight vector: $\bold{w} \larr \bold{w} + \alpha(y - \hat{y})\bold{x}$. 
    ($\alpha$ is a learning rate). Note that $y - \hat{y} = 0$ if there are no errors (and so there is no update
    to the weights vector).
- Repeat until there are no errors. Note that this repetition will go on forever
if the data is not [linearly separable](202210210913.md) as there will always be
some error that the algorithm is looking to correct.
