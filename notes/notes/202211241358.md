# Principal component analysis

To find the first PC, i.e. a single unit vector $\bold{u}$ capturing greatest
variance

$$
\tilde{x}_i = \bold{u} \cdot \bold{x}_i
$$

Expressed as a vector in original coordinates:

$$
\tilde{\bold{x}}_i = \tilde{x}_i \bold{u} = (\bold{u} \cdot \bold{x}_i)\bold{u}
$$

With

$$
\begin{align*}
\text{var}(\tilde{\bold{X}}) &= \frac{1}{n}\sum_{i} \tilde{x}_i^2 \\[0.5em]
&= \frac{1}{n}\bold{u}^{\top}\bold{X}^{\top}\bold{X}\bold{u} \\[0.5em]
&= \bold{u}^{\top}\boldsymbol{\Sigma}\bold{u} \\[0.5em]
\end{align*}
$$

Note that this assumes that the data are centred.

We want to $\bold{u}$ that maximises the variance

$$
\max_{\bold{u}} \bold{u}^{\top}\boldsymbol{\Sigma}\bold{u}
$$

Subject to $\|\bold{u}\| = 1$. This results in
$\bold{u}^{\top}\boldsymbol{\Sigma}\bold{u} = \lambda$ where $\lambda$ is an
[eigenvector](202210271132.md).

Eventually we have

$$
\tilde{\bold{X}} = \bold{X}\bold{U}
$$

Where

$$
\bold{U} \in \R^{d \times d} \hspace{1em} \text{cols eigenvectors of } \bold{X}^{\top}\bold{X}
$$

Can also use [singular value decomposition](202211241407.md) to do the above,
with $\bold{X} = \bold{V}\bold{D}\bold{U}^{\top}$, we have that
$\tilde{\bold{X}} = \bold{V}\bold{D}$. Sometimes the SVD approach is preferred
as it can be more numerically stable.
