# Analytic Optimisation

Looking for the minimum of a loss function. Recall that the derivatives of a
function are 0 at its extremes, its minimum and maximum. Can describe the
gradient of a loss function $L$ with respect to the parameters $\theta$ as
$\nabla _\theta L$. Sometimes, albeit rarely,  you'll be able to solve $\nabla
_\theta L = 0$, which gives us the desired $\theta$. Often the equation has no
solutions.
